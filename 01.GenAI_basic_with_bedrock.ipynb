{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658ffbb7",
   "metadata": {},
   "source": [
    "# 생성형 AI 기본 API 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b4a87",
   "metadata": {},
   "source": [
    "## 1. 미리 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ab366",
   "metadata": {},
   "source": [
    "### 1.1 프로그램 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2322e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3                                    1.40.40\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지 설치\n",
    "! pip install --upgrade boto3  > /dev/null 2>&1\n",
    "! pip list | egrep 'boto3' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646da282",
   "metadata": {},
   "source": [
    "### 1.2 인증 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9985fb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS 자격 증명 확인 완료\n",
      "리전: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "import json\n",
    "\n",
    "# 프로그램의 시간측정을 위한 Class 선언 \n",
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        print(\"\\n\\n-----------\")\n",
    "        print(f\"모델 실행 시간: {time.time() - self.start:.2f}초 \\n\")\n",
    "        \n",
    "# AWS 자격 증명 확인\n",
    "try:\n",
    "    session = boto3.Session()\n",
    "    credentials = session.get_credentials()\n",
    "    print(\"AWS 자격 증명 확인 완료\")\n",
    "    print(f\"리전: {session.region_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"AWS 자격 증명 오류: {e}\")\n",
    "    print(\"AWS CLI를 사용하여 자격 증명을 설정해주세요: aws configure\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03b1b68",
   "metadata": {},
   "source": [
    "### 1.3 Bedrock 클라이언트 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d47556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = session.client('bedrock-runtime')\n",
    "bedrock2 = session.client('bedrock')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d8296e",
   "metadata": {},
   "source": [
    "### 1.4 Bedrock이 제공하는 모델 확인 하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7fbaadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 모델 상세 정보 ===\n",
      "모델 ID: stability.stable-image-remove-background-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-remove-background-v1:0\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: stability.stable-image-style-guide-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-style-guide-v1:0\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: stability.stable-image-control-sketch-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-control-sketch-v1:0\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-sonnet-4-20250514-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-sonnet-4-20250514-v1:0\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: stability.stable-image-erase-object-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-erase-object-v1:0\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: stability.stable-image-control-structure-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-control-structure-v1:0\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: stability.stable-image-search-recolor-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-search-recolor-v1:0\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: openai.gpt-oss-120b-1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/openai.gpt-oss-120b-1:0\n",
      "제공업체: OpenAI\n",
      "============================================================\n",
      "모델 ID: twelvelabs.pegasus-1-2-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/twelvelabs.pegasus-1-2-v1:0\n",
      "제공업체: TwelveLabs\n",
      "============================================================\n",
      "모델 ID: stability.stable-style-transfer-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-style-transfer-v1:0\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: twelvelabs.marengo-embed-2-7-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/twelvelabs.marengo-embed-2-7-v1:0\n",
      "제공업체: TwelveLabs\n",
      "============================================================\n",
      "모델 ID: stability.stable-image-search-replace-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-search-replace-v1:0\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: qwen.qwen3-coder-30b-a3b-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/qwen.qwen3-coder-30b-a3b-v1:0\n",
      "제공업체: Qwen\n",
      "============================================================\n",
      "모델 ID: qwen.qwen3-32b-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/qwen.qwen3-32b-v1:0\n",
      "제공업체: Qwen\n",
      "============================================================\n",
      "모델 ID: stability.stable-image-inpaint-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-inpaint-v1:0\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: openai.gpt-oss-20b-1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/openai.gpt-oss-20b-1:0\n",
      "제공업체: OpenAI\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-opus-4-1-20250805-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-opus-4-1-20250805-v1:0\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: amazon.titan-tg1-large\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-image-generator-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-image-generator-v1\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-image-generator-v2:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v2:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-premier-v1:0:8k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:8k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-premier-v1:0:20k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:20k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-premier-v1:0:1000k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:1000k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-premier-v1:0:mm\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:mm\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-premier-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-pro-v1:0:24k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0:24k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-pro-v1:0:300k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0:300k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-pro-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-lite-v1:0:24k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0:24k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-lite-v1:0:300k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0:300k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-lite-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-canvas-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-canvas-v1:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-reel-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-reel-v1:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-reel-v1:1\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-reel-v1:1\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-micro-v1:0:24k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0:24k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-micro-v1:0:128k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0:128k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-micro-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.nova-sonic-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-sonic-v1:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-embed-g1-text-02\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-text-lite-v1:0:4k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-text-lite-v1\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-text-express-v1:0:8k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-text-express-v1\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-embed-text-v1:2:8k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-embed-text-v1\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-embed-text-v2:0:8k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0:8k\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-embed-text-v2:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-embed-image-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: amazon.titan-embed-image-v1\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1\n",
      "제공업체: Amazon\n",
      "============================================================\n",
      "모델 ID: stability.stable-diffusion-xl-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1:0\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: stability.stable-diffusion-xl-v1\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1\n",
      "제공업체: Stability AI\n",
      "============================================================\n",
      "모델 ID: ai21.jamba-1-5-large-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-large-v1:0\n",
      "제공업체: AI21 Labs\n",
      "============================================================\n",
      "모델 ID: ai21.jamba-1-5-mini-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-mini-v1:0\n",
      "제공업체: AI21 Labs\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-instant-v1:2:100k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-v2:0:18k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-v2:0:100k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-v2:1:18k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-v2:1:200k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-haiku-20240307-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-opus-20240229-v1:0:12k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:12k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-opus-20240229-v1:0:28k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:28k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-opus-20240229-v1:0:200k\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:200k\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-opus-20240229-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-5-sonnet-20241022-v2:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20241022-v2:0\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-7-sonnet-20250219-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-7-sonnet-20250219-v1:0\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-3-5-haiku-20241022-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-haiku-20241022-v1:0\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: anthropic.claude-opus-4-20250514-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-opus-4-20250514-v1:0\n",
      "제공업체: Anthropic\n",
      "============================================================\n",
      "모델 ID: cohere.command-r-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-v1:0\n",
      "제공업체: Cohere\n",
      "============================================================\n",
      "모델 ID: cohere.command-r-plus-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-plus-v1:0\n",
      "제공업체: Cohere\n",
      "============================================================\n",
      "모델 ID: cohere.embed-english-v3:0:512\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3:0:512\n",
      "제공업체: Cohere\n",
      "============================================================\n",
      "모델 ID: cohere.embed-english-v3\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3\n",
      "제공업체: Cohere\n",
      "============================================================\n",
      "모델 ID: cohere.embed-multilingual-v3:0:512\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3:0:512\n",
      "제공업체: Cohere\n",
      "============================================================\n",
      "모델 ID: cohere.embed-multilingual-v3\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3\n",
      "제공업체: Cohere\n",
      "============================================================\n",
      "모델 ID: deepseek.r1-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/deepseek.r1-v1:0\n",
      "제공업체: DeepSeek\n",
      "============================================================\n",
      "모델 ID: meta.llama3-8b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-8b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: meta.llama3-70b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-70b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: meta.llama3-1-8b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-1-8b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: meta.llama3-1-70b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-1-70b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: meta.llama3-2-11b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-11b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: meta.llama3-2-90b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-90b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: meta.llama3-2-1b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-1b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: meta.llama3-2-3b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-3b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: meta.llama3-3-70b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-3-70b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: meta.llama4-scout-17b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-scout-17b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: meta.llama4-maverick-17b-instruct-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-maverick-17b-instruct-v1:0\n",
      "제공업체: Meta\n",
      "============================================================\n",
      "모델 ID: mistral.mistral-7b-instruct-v0:2\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-7b-instruct-v0:2\n",
      "제공업체: Mistral AI\n",
      "============================================================\n",
      "모델 ID: mistral.mixtral-8x7b-instruct-v0:1\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/mistral.mixtral-8x7b-instruct-v0:1\n",
      "제공업체: Mistral AI\n",
      "============================================================\n",
      "모델 ID: mistral.mistral-large-2402-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-large-2402-v1:0\n",
      "제공업체: Mistral AI\n",
      "============================================================\n",
      "모델 ID: mistral.mistral-small-2402-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-small-2402-v1:0\n",
      "제공업체: Mistral AI\n",
      "============================================================\n",
      "모델 ID: mistral.pixtral-large-2502-v1:0\n",
      "모델 ARN: arn:aws:bedrock:us-east-1::foundation-model/mistral.pixtral-large-2502-v1:0\n",
      "제공업체: Mistral AI\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = bedrock2.list_foundation_models()\n",
    "\n",
    "print(\"=== 모델 상세 정보 ===\")\n",
    "for model in response['modelSummaries']:\n",
    "    print(f\"모델 ID: {model['modelId']}\")\n",
    "    print(f\"모델 ARN: {model['modelArn']}\")\n",
    "    print(f\"제공업체: {model['providerName']}\")\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee92a5",
   "metadata": {},
   "source": [
    "### 1.5 이 프로그램에서 사용할 기본 모델 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5baa614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model ID] claude-3-5-haiku : us.anthropic.claude-3-5-haiku-20241022-v1:0\n",
      "[Current Region]: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# 현재 리전 확인\n",
    "current_region = boto3.Session().region_name\n",
    "\n",
    "# 현재 리전에 맞는 Model ID 자동 검색\n",
    "models = bedrock2.list_foundation_models()['modelSummaries']\n",
    "\n",
    "base_model=\"\"\n",
    "# 버지니아 리전인 경우 Cross-region inference 사용\n",
    "if current_region == 'us-east-1':\n",
    "    base_model = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\"\n",
    "else:\n",
    "    find_models = next((m for m in models if 'claude-3-5-haiku' in m['modelId'].lower()), None)\n",
    "    base_model = find_models['modelId']\n",
    "\n",
    "print(\"[Model ID] claude-3-5-haiku :\", base_model)\n",
    "print(\"[Current Region]:\", current_region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dec011",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Bedrock Invoke API 호출 \n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/inference-invoke.html \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca69ea",
   "metadata": {},
   "source": [
    "### 2.1 Claude model 용 Helper함수 선언후 모델 호출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf1e7875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------\n",
      "모델 실행 시간: 5.88초 \n",
      "\n",
      "김치 볶음밥을 맛있게 만드는 방법을 알려드리겠습니다.\n",
      "\n",
      "재료:\n",
      "- 밥\n",
      "- 김치\n",
      "- 돼지고기 (선택사항)\n",
      "- 계란\n",
      "- 식용유\n",
      "- 소금, 후추\n",
      "\n",
      "조리 순서:\n",
      "1. 김치를 잘게 썰어주세요\n",
      "2. 팬에 식용유를 두르고 중불로 달군 후\n",
      "3. 김치와 돼지고기를 볶아주세요\n",
      "4. 밥을 넣고 함께 볶으면서 고루 섞어주세요\n",
      "5. 마지막에 계란을 살짝 부어 볶아주세요\n",
      "6. 소금, 후추로 간을 맞춰주세요\n",
      "\n",
      "팁:\n",
      "- 김치는 숙성된 김치가 더 맛있어요\n",
      "- 밥은 차갑고 단단한 밥이 볶음밥에 좋습니다\n",
      "- 참기름을 살짝 뿌리면 풍미가 더해집니다\n",
      "\n",
      "[모델 실행 정보] ------------------------------------------\n",
      "input_tokens : 71\n",
      "output_tokens : 322\n"
     ]
    }
   ],
   "source": [
    "def test_invokeapi_claude(message, system=\"\", history=None ,display=True):\n",
    "    if history:\n",
    "        history.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": message}]})\n",
    "        body = json.dumps({\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 1500,\n",
    "            \"temperature\": 0.5,\n",
    "            \"system\": system,\n",
    "            \"messages\": history\n",
    "            })\n",
    "    else:\n",
    "        body = json.dumps({\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 1500,\n",
    "            \"temperature\": 0.5,\n",
    "            \"system\": system,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": message}]\n",
    "            })   \n",
    "\n",
    "    with Timer():\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=base_model,\n",
    "            # modelId=\"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "            body=body\n",
    "        )\n",
    "\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    output_text = response_body['content'][0]['text']\n",
    "    \n",
    "    if display:\n",
    "        print(output_text)\n",
    "        print(\"\\n[모델 실행 정보] ------------------------------------------\")\n",
    "        for key in ['input_tokens', 'output_tokens']:\n",
    "            print(f\"{key} : {response_body.get('usage', {}).get(key, 0)}\")\n",
    "\n",
    "    return output_text\n",
    "\n",
    "Ret=test_invokeapi_claude(message=\"김치 볶음밥은 어떻게 만들어야 하나요?\", \n",
    "            system=\"당신은 한식 요리 전문가 입니다. 전문가로써의 정중한 답변을 해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e0574",
   "metadata": {},
   "source": [
    "### 2.3 Claude 모델의 Stream 방식 모델 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4c9e61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------\n",
      "모델 실행 시간: 1.35초 \n",
      "\n",
      "김치 볶음밥을 맛있게 만드는 방법을 알려드리겠습니다.\n",
      "\n",
      "재료:\n",
      "- 밥\n",
      "- 김치\n",
      "- 돼지고기 또는 햄\n",
      "- 계란\n",
      "- 파\n",
      "- 참기름\n",
      "- 간장\n",
      "- 소금, 후추\n",
      "\n",
      "조리 순서:\n",
      "1. 김치를 잘게 다져주세요\n",
      "2. 팬에 기름을 두르고 김치와 고기를 볶아주세요\n",
      "3. 밥을 넣고 함께 볶으면서 간장으로 간을 맞춰주세요\n",
      "4. 마지막에 계란을 살짝 프라이해서 올려주세요\n",
      "5. 파를 다져 위에 뿌리고 참기름을 살짝 둘러주세요\n",
      "\n",
      "팁: 밥은 차가운 밥이 더 맛있으며, 팬을 중불로 해주세요.\n",
      "\n",
      "--모델 실행 정보 --------------------------------------------------------------\n",
      "inputTokens : 0\n",
      "outputTokens : 285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'김치 볶음밥을 맛있게 만드는 방법을 알려드리겠습니다.\\n\\n재료:\\n- 밥\\n- 김치\\n- 돼지고기 또는 햄\\n- 계란\\n- 파\\n- 참기름\\n- 간장\\n- 소금, 후추\\n\\n조리 순서:\\n1. 김치를 잘게 다져주세요\\n2. 팬에 기름을 두르고 김치와 고기를 볶아주세요\\n3. 밥을 넣고 함께 볶으면서 간장으로 간을 맞춰주세요\\n4. 마지막에 계란을 살짝 프라이해서 올려주세요\\n5. 파를 다져 위에 뿌리고 참기름을 살짝 둘러주세요\\n\\n팁: 밥은 차가운 밥이 더 맛있으며, 팬을 중불로 해주세요.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_invokeapi_claude_stream(message, system=\"\"):\n",
    "    body = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1500,\n",
    "        \"temperature\": 0.5,\n",
    "        \"system\": system,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": message}]\n",
    "    })\n",
    "\n",
    "    with Timer():\n",
    "        response = bedrock.invoke_model_with_response_stream(\n",
    "            modelId=base_model,\n",
    "            body=body\n",
    "        )\n",
    "\n",
    "    # 스트림 응답 처리\n",
    "    stream = response.get(\"body\")\n",
    "    full_text = \"\"\n",
    "\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get(\"chunk\")\n",
    "            if chunk:\n",
    "                chunk_json = json.loads(chunk.get(\"bytes\").decode())\n",
    "\n",
    "                # 메시지 시작 처리\n",
    "                if chunk_json.get(\"type\") == \"message_start\":\n",
    "                    continue\n",
    "\n",
    "                # 콘텐츠 블록 시작 처리\n",
    "                elif chunk_json.get(\"type\") == \"content_block_start\":\n",
    "                    continue\n",
    "\n",
    "                # 콘텐츠 블록 델타 처리 (실제 텍스트)\n",
    "                elif chunk_json.get(\"type\") == \"content_block_delta\":\n",
    "                    delta = chunk_json.get(\"delta\", {})\n",
    "                    if delta.get(\"type\") == \"text_delta\":\n",
    "                        delta_text = delta.get(\"text\", \"\")\n",
    "                        print(delta_text, end=\"\", flush=True)\n",
    "                        full_text += delta_text\n",
    "\n",
    "                # 메시지 델타 처리 (사용량 정보)\n",
    "                elif chunk_json.get(\"type\") == \"message_delta\":\n",
    "                    usage = chunk_json.get(\"usage\")\n",
    "                    if usage:\n",
    "                        print(\"\\n\\n--모델 실행 정보 --------------------------------------------------------------\")\n",
    "                        print(f\"inputTokens : {usage.get('input_tokens', 0)}\")\n",
    "                        print(f\"outputTokens : {usage.get('output_tokens', 0)}\")\n",
    "\n",
    "    return full_text\n",
    "\n",
    "# 사용 예시\n",
    "test_invokeapi_claude_stream(\n",
    "    message=\"김치 볶음밥은 어떻게 만들어야 하나요?\",\n",
    "    system=\"당신은 한식 요리 전문가 입니다. 전문가로써의 정중한 답변을 해주세요.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3777c1a",
   "metadata": {},
   "source": [
    "### 2.4 모델이 대화를 기억 하는지 테스트 \n",
    "- 기본적으로 모델은 기억 기능이 없다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5590d0f2",
   "metadata": {},
   "source": [
    "#### 1) 모델에게 내가 누구 인지 정보를 준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2be3049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------\n",
      "모델 실행 시간: 1.41초 \n",
      "\n",
      "네, 알겠습니다. 앞으로 재구님이라고 부르겠습니다. 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "ret=test_invokeapi_claude(message=\"나는 조재구라고해 앞으로 나를 재구님 이라고 해줘!\",display=False) \n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a5ea3f",
   "metadata": {},
   "source": [
    "#### 2) 내가 누구 인지 물어본다\n",
    "- 모른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "679d11ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------\n",
      "모델 실행 시간: 1.80초 \n",
      "\n",
      "제가 당신의 이름을 들은 적이 없습니다. 제 이름은 Claude입니다.\n"
     ]
    }
   ],
   "source": [
    "ret=test_invokeapi_claude(message=\"나에 이름이 무엇이라고 했지?\",display=False) \n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d0bec",
   "metadata": {},
   "source": [
    "### 2.5 모델이 대화의 내용을 기억하게 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df845283",
   "metadata": {},
   "source": [
    "#### 1) 대화를 기억할 저장소를 만든다 \n",
    "- 이 저장소에 모델에게 입력한 내용과 출력한 내용을 모두 기록하도록 한다.\n",
    "- List 구조 방식으로 기록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d90c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기억 장소를 하나 만든다.\n",
    "history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fd631",
   "metadata": {},
   "source": [
    "#### 2) 첫 번째 질문과 답변을 얻는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d06df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[질문1] 나에 이름은  조재구 라고 한다. 앞으로 나를 재구님 이라고 불러줘!\n",
      "\n",
      "\n",
      "-----------\n",
      "모델 실행 시간: 1.28초 \n",
      "\n",
      "\n",
      "[응답 1번째:] -----------------------\n",
      "알겠습니다, 재구님. 앞으로 재구님이라고 부르겠습니다.\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 질문과 응답 \n",
    "MessageNumber1=\"나에 이름은  조재구 라고 한다. 앞으로 나를 재구님 이라고 불러줘!\"\n",
    "print(\"\\n[질문1]\",MessageNumber1)\n",
    "assistant_messages=test_invokeapi_claude(message=MessageNumber1,history=history,display=False) \n",
    "print(\"[응답 1번째:] -----------------------\")\n",
    "print(assistant_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1425b0",
   "metadata": {},
   "source": [
    "#### 3) 첫 번째 대화 내용을 기억장소에 기록한다.\n",
    "- 모델에게 요청한 정보와 응답한 메세지를 기록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd56f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 응답을 기억 장소에 저장한다. \n",
    "history.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": assistant_messages}]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65b0f13",
   "metadata": {},
   "source": [
    "#### 4) 두번째 질문을 한다. 이때 기억한 대화 정보도 함께 요청한다.\n",
    "- 아래 요청할때 history=history 라는 변수 선언이 보입니다. 위에 Helper 함수에 histoy 값을 이용해서 Body를 만들도록 하고 있습니다.\n",
    "- 이번에 응답에서 \"재구님\" 이라고 정확하게 기억하는 것을 알수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bc6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[질문2] 나에 이름이 무엇이라고 했지?\n",
      "\n",
      "[응답 2번째:] -----------------------\n",
      "\n",
      "\n",
      "-----------\n",
      "모델 실행 시간: 1.14초 \n",
      "\n",
      "알겠습니다, 재구님. 앞으로 재구님이라고 부르겠습니다.\n"
     ]
    }
   ],
   "source": [
    "# 두번째 질문을 진행한다.\n",
    "MessageNumber2=\"나에 이름이 무엇이라고 했지?\"\n",
    "print(\"\\n[질문2]\",MessageNumber2)\n",
    "print(\"[응답 2번째:] -----------------------\")\n",
    "assistant_messages=test_invokeapi_claude(message=MessageNumber1,history=history,display=False) \n",
    "print(assistant_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab931ac",
   "metadata": {},
   "source": [
    "#### 5) 두번째 대화 내용도 기억장소에 기록한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82db4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 응답을 기억 장소에 추가 저장한다. \n",
    "history.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": MessageNumber2}]})\n",
    "history.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": assistant_messages}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa9c3fc",
   "metadata": {},
   "source": [
    "#### 6) 기억 장소에 기록된 내용을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a67b431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': [{'type': 'text', 'text': '나에 이름은  조재구 라고 한다. 앞으로 나를 재구님 이라고 불러줘!'}]}\n",
      "{'role': 'assistant', 'content': [{'type': 'text', 'text': '알겠습니다, 재구님. 앞으로 재구님이라고 부르겠습니다.'}]}\n",
      "{'role': 'user', 'content': [{'type': 'text', 'text': '나에 이름은  조재구 라고 한다. 앞으로 나를 재구님 이라고 불러줘!'}]}\n",
      "{'role': 'user', 'content': [{'type': 'text', 'text': '나에 이름이 무엇이라고 했지?'}]}\n",
      "{'role': 'assistant', 'content': [{'type': 'text', 'text': '알겠습니다, 재구님. 앞으로 재구님이라고 부르겠습니다.'}]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 현재 기억장소의 내용을 표시한다.\n",
    "for item in history:\n",
    "    print(item)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8676b806",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c0d10d",
   "metadata": {},
   "source": [
    "## 3. Converse API \n",
    "- 대화를 기능을 편리하게 제공되는 API (Chatbot선언)\n",
    "- 모델마다 다르게 Invoke API를 사용해야 하는 것과 다르게 통일된 API를 사용함 \n",
    "- https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589bf49",
   "metadata": {},
   "source": [
    "### 3.1 Parameter 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b080ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt 선언\n",
    "system_prompts = [{\"text\": \"당신은 한식 요리 전문가 입니다. 전문가로써의 정중한 답변을 해주세요.\"}]\n",
    "\n",
    "# 기억 기능을 위한 연속적인 API 호출과 출력의 메세지들을 위한 \n",
    "messages = []\n",
    "\n",
    "# 기본 Inference parameters 선언 , 모델마다 값이 다를수 있음. \n",
    "inference_config = {\"temperature\": 0.5}\n",
    "\n",
    "# 추가적인 Inference parameters, 모델마다 값이 다를수 있음. \n",
    "additional_model_fields = {\"top_p\": 0.9}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499285d1",
   "metadata": {},
   "source": [
    "### 3.2 Converse API 로 모델 호출 - 첫번째 질의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3e2489e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 김치 찌개는 한국인들이 가장 사랑하는 대표적인 요리 중 하나입니다. 정통 김치 찌개 레시피를 알려드리겠습니다.\n",
      "\n",
      "재료:\n",
      "- 김치 1컵 (잘 익은 김치)\n",
      "- 돼지고기 200g (삼겹살 또는 목살)\n",
      "- 두부 1모\n",
      "- 대파 1대\n",
      "- 고춧가루, 국간장, 다진 마늘\n",
      "\n",
      "조리 순서:\n",
      "1. 김치를 적당한 크기로 잘라주세요.\n",
      "2. 팬에 돼지고기를 살짝 볶아주세요.\n",
      "3. 김치를 넣고 함께 볶아주세요.\n",
      "4. 물을 붓고 끓이면서 간을 맞춰주세요.\n",
      "5. 두부와 대파를 넣고 마무리합니다.\n",
      "\n",
      "팁: 김치는 잘 익은 것을 사용하면 더욱 맛있습니다.\n",
      "\n",
      "맛있게 드세요!\n",
      "------------------ MetaData ----------------------------------\n",
      "inputTokens: 76\n",
      "outputTokens: 335\n",
      "totalTokens: 411\n",
      "cacheReadInputTokens: 0\n",
      "cacheWriteInputTokens: 0\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 질문을 \n",
    "messages.append( \n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"김치 찌개를 끓이고 싶어요! 레시피를 알려주세요\"}]\n",
    "    }\n",
    ")\n",
    "\n",
    "response = bedrock.converse(\n",
    "        modelId=base_model,\n",
    "        messages=messages,\n",
    "        system=system_prompts,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields\n",
    "    )\n",
    "\n",
    "output_message = response['output']['message']\n",
    "\n",
    "# 출력된 데이터를 첫번째 질문의 메세지 영역에 추가 한다.\n",
    "messages.append(output_message)\n",
    "print(output_message['content'][0]['text'])\n",
    "\n",
    "print(\"------------------ MetaData ----------------------------------\")\n",
    "Usage=response.get(\"usage\")\n",
    "for key, value in Usage.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1048a17c",
   "metadata": {},
   "source": [
    "### 3.3 Converse API 로 모델 호출 - 두번째 질의\n",
    "- 주의 : 모델 실행후 Input 토큰수를 확인해야함,\n",
    "- 첫번째 모델에게 입력/출력 값을 두번째 모델의 입력으로 전달함.\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    Input[첫 번째 질문] --> Model1[모델 호출]\n",
    "    Model1 --> Output1[첫 번째 모델 출력]\n",
    "    \n",
    "    Input --> Combine[첫번째 질문 + 답 + 두번째 질문 입력 결합 ]\n",
    "    Output1 --> Combine\n",
    "    \n",
    "    Combine --> Model2[두 번째 모델]\n",
    "    Model2 --> FinalOutput[최종 출력]\n",
    "    \n",
    "    style Input fill:#42a5f5,color:#fff\n",
    "    style Model1 fill:#ab47bc,color:#fff\n",
    "    style Output1 fill:#ffa726,color:#000\n",
    "    style Combine fill:#ffee58,color:#000\n",
    "    style Model2 fill:#ab47bc,color:#fff\n",
    "    style FinalOutput fill:#66bb6a,color:#fff\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dfbd4703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김치 찌개의 주요 영양성분을 상세히 알려드리겠습니다.\n",
      "\n",
      "🥬 영양성분 (1인분 기준):\n",
      "- 칼로리: 약 250-300kcal\n",
      "- 단백질: 15-20g\n",
      "- 지방: 15-18g\n",
      "- 탄수화물: 10-15g\n",
      "\n",
      "🌟 주요 영양소:\n",
      "1. 단백질 \n",
      "- 돼지고기: 근육 발달, 면역력 강화\n",
      "- 두부: 식물성 단백질 공급\n",
      "\n",
      "2. 비타민\n",
      "- 비타민 A, C: 면역력 증진\n",
      "- 비타민 B군: 대사 활성화\n",
      "\n",
      "3. 무기질\n",
      "- 칼슘: 뼈 건강\n",
      "- 철분: 혈액 순환\n",
      "- 칼륨: 혈압 조절\n",
      "\n",
      "4. 김치의 특별한 영양\n",
      "- 프로바이오틱스: 장 건강 개선\n",
      "- 항산화 성분: 노화 방지\n",
      "\n",
      "건강하고 맛있는 한 끼 식사가 되시길 바랍니다!\n",
      "------------------ MetaData ----------------------------------\n",
      "inputTokens: 438\n",
      "outputTokens: 339\n",
      "totalTokens: 777\n",
      "cacheReadInputTokens: 0\n",
      "cacheWriteInputTokens: 0\n"
     ]
    }
   ],
   "source": [
    "# 앞선 메세지에 2번째 질문을 추가한다. \n",
    "messages.append(  \n",
    "   {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"이 레시피에 들이가는 영양성분을 알려주세요\"}]\n",
    "    }\n",
    ")\n",
    "\n",
    "response = bedrock.converse(\n",
    "        modelId=base_model,\n",
    "        messages=messages,\n",
    "        system=system_prompts,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields\n",
    "    )\n",
    "\n",
    "output_message = response['output']['message']\n",
    "\n",
    "# 출력된 데이터를 메세지 영역에 추가 한다.\n",
    "messages.append(output_message)\n",
    "print(output_message['content'][0]['text'])\n",
    "\n",
    "print(\"------------------ MetaData ----------------------------------\")\n",
    "Usage=response.get(\"usage\")\n",
    "for key, value in Usage.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95947c71",
   "metadata": {},
   "source": [
    "### 3.4 대화 기록 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8f66f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: user\n",
      "-----------------\n",
      "Text: 김치 찌개를 끓이고 싶어요! 레시피를 알려주세요\n",
      "----------------------------------------\n",
      "\n",
      "Role: assistant\n",
      "-----------------\n",
      "Text: 안녕하세요! 김치 찌개는 한국인들이 가장 사랑하는 대표적인 요리 중 하나입니다. 정통 김치 찌개 레시피를 알려드리겠습니다.\n",
      "\n",
      "재료:\n",
      "- 김치 1컵 (잘 익은 김치)\n",
      "- 돼지고기 200g (삼겹살 또는 목살)\n",
      "- 두부 1모\n",
      "- 대파 1대\n",
      "- 고춧가루, 국간장, 다진 마늘\n",
      "\n",
      "조리 순서:\n",
      "1. 김치를 적당한 크기로 잘라주세요.\n",
      "2. 팬에 돼지고기를 살짝 볶아주세요.\n",
      "3. 김치를 넣고 함께 볶아주세요.\n",
      "4. 물을 붓고 끓이면서 간을 맞춰주세요.\n",
      "5. 두부와 대파를 넣고 마무리합니다.\n",
      "\n",
      "팁: 김치는 잘 익은 것을 사용하면 더욱 맛있습니다.\n",
      "\n",
      "맛있게 드세요!\n",
      "----------------------------------------\n",
      "\n",
      "Role: user\n",
      "-----------------\n",
      "Text: 이 레시피에 들이가는 영양성분을 알려주세요\n",
      "----------------------------------------\n",
      "\n",
      "Role: assistant\n",
      "-----------------\n",
      "Text: 김치 찌개의 주요 영양성분을 상세히 알려드리겠습니다.\n",
      "\n",
      "🥬 영양성분 (1인분 기준):\n",
      "- 칼로리: 약 250-300kcal\n",
      "- 단백질: 15-20g\n",
      "- 지방: 15-18g\n",
      "- 탄수화물: 10-15g\n",
      "\n",
      "🌟 주요 영양소:\n",
      "1. 단백질 \n",
      "- 돼지고기: 근육 발달, 면역력 강화\n",
      "- 두부: 식물성 단백질 공급\n",
      "\n",
      "2. 비타민\n",
      "- 비타민 A, C: 면역력 증진\n",
      "- 비타민 B군: 대사 활성화\n",
      "\n",
      "3. 무기질\n",
      "- 칼슘: 뼈 건강\n",
      "- 철분: 혈액 순환\n",
      "- 칼륨: 혈압 조절\n",
      "\n",
      "4. 김치의 특별한 영양\n",
      "- 프로바이오틱스: 장 건강 개선\n",
      "- 항산화 성분: 노화 방지\n",
      "\n",
      "건강하고 맛있는 한 끼 식사가 되시길 바랍니다!\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "            print(f\"Role: {message['role']}\")\n",
    "            print(\"-----------------\")\n",
    "            for content in message['content']:\n",
    "                print(f\"Text: {content['text']}\")\n",
    "                print(\"-\" * 40)\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd3653",
   "metadata": {},
   "source": [
    "### 3.4 Converse stream API 사용 \n",
    "- Strem 형식의 출력을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "570d8a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Role: assistant\n",
      "김치 찌개 요리 가이드 요약\n",
      "\n",
      "📋 레시피\n",
      "재료:\n",
      "- 김치 1컵\n",
      "- 돼지고기 200g\n",
      "- 두부 1모\n",
      "- 대파 1대\n",
      "- 고춧가루, 국간장, 다진 마늘\n",
      "\n",
      "조리 순서:\n",
      "1. 김치 자르기\n",
      "2. 돼지고기 볶기\n",
      "3. 김치와 함께 볶기\n",
      "4. 물 붓고 끓이기\n",
      "5. 두부, 대파 넣고 마무리\n",
      "\n",
      "🥬 영양성분 (1인분 기준)\n",
      "- 칼로리: 250-300kcal\n",
      "- 단백질: 15-20g\n",
      "- 지방: 15-18g\n",
      "- 탄수화물: 10-15g\n",
      "\n",
      "주요 영양소:\n",
      "- 단백질: 근육 발달\n",
      "- 비타민: 면역력 증진\n",
      "- 무기질: 뼈 건강, 혈액 순환\n",
      "- 김치: 장 건강, 항산화 효과\n",
      "\n",
      "맛있고 건강한 한식 요리를 즐기세요!\n",
      "Stop reason: end_turn\n",
      "\n",
      "Token usage\n",
      "Input tokens: 795\n",
      ":Output tokens: 333\n",
      ":Total tokens: 1128\n",
      "Latency: 4901 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# 앞선 메세지에 3번째 질문을 추가한다. \n",
    "messages.append(  \n",
    "   {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"지금까지 내용을 정리해줘\"}]\n",
    "    }\n",
    ")\n",
    "\n",
    "response = bedrock.converse_stream(\n",
    "        modelId=base_model,\n",
    "        messages=messages,\n",
    "        system=system_prompts,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields\n",
    "    )\n",
    "\n",
    "# Strem 형식의 출력 \n",
    "stream = response.get('stream')\n",
    "if stream:\n",
    "    for event in stream:\n",
    "\n",
    "        if 'messageStart' in event:\n",
    "            print(f\"\\nRole: {event['messageStart']['role']}\")\n",
    "\n",
    "        if 'contentBlockDelta' in event:\n",
    "            print(event['contentBlockDelta']['delta']['text'], end=\"\")\n",
    "\n",
    "        if 'messageStop' in event:\n",
    "            print(f\"\\nStop reason: {event['messageStop']['stopReason']}\")\n",
    "\n",
    "        if 'metadata' in event:\n",
    "            metadata = event['metadata']\n",
    "            if 'usage' in metadata:\n",
    "                print(\"\\nToken usage\")\n",
    "                print(f\"Input tokens: {metadata['usage']['inputTokens']}\")\n",
    "                print(\n",
    "                    f\":Output tokens: {metadata['usage']['outputTokens']}\")\n",
    "                print(f\":Total tokens: {metadata['usage']['totalTokens']}\")\n",
    "            if 'metrics' in event['metadata']:\n",
    "                print(\n",
    "                    f\"Latency: {metadata['metrics']['latencyMs']} milliseconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09aaf1d",
   "metadata": {},
   "source": [
    "## 4. 프롬프트 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45603d8",
   "metadata": {},
   "source": [
    "### 4.1 프롬프트 실행을 위한 Model 함수 (Helper 함수) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36664afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelInvoke(user_messages, system_prompt=\"\", inference_config={\"temperature\": 0.5}, additional_model_fields={\"top_k\": 200},modelId=base_model):\n",
    "    # 메시지 구성\n",
    "    messages = [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": [{\"text\": user_messages}]\n",
    "    }]\n",
    "\n",
    "    # 시스템 프롬프트가 있는 경우에만 추가\n",
    "    if system_prompt:\n",
    "        system_prompts = [{\"text\": system_prompt}]\n",
    "        response = bedrock.converse_stream(\n",
    "            modelId=modelId,\n",
    "            messages=messages,\n",
    "            system=system_prompts,\n",
    "            inferenceConfig=inference_config,\n",
    "            additionalModelRequestFields=additional_model_fields\n",
    "        )\n",
    "    else:\n",
    "        response = bedrock.converse_stream(\n",
    "            modelId=modelId, \n",
    "            messages=messages,\n",
    "            inferenceConfig=inference_config,\n",
    "            additionalModelRequestFields=additional_model_fields\n",
    "        )\n",
    "\n",
    "    # Stream 형식의 출력\n",
    "    stream = response.get('stream')\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "\n",
    "            if 'messageStart' in event:\n",
    "                print(f\"\\nRole: {event['messageStart']['role']}\")\n",
    "\n",
    "            if 'contentBlockDelta' in event:\n",
    "                print(event['contentBlockDelta']['delta']['text'], end=\"\")\n",
    "\n",
    "            if 'messageStop' in event:\n",
    "                print(f\"\\nStop reason: {event['messageStop']['stopReason']}\")\n",
    "\n",
    "            if 'metadata' in event:\n",
    "                print(\"\\n---------- MetaData --------------\")\n",
    "                metadata = event['metadata']\n",
    "\n",
    "                if 'usage' in metadata:\n",
    "                    print(f\"Input tokens: {metadata['usage']['inputTokens']}\")\n",
    "                    print(f\"Output tokens: {metadata['usage']['outputTokens']}\")\n",
    "                    print(f\"Total tokens: {metadata['usage']['totalTokens']}\")\n",
    "                if 'metrics' in event['metadata']:\n",
    "                    print(f\"Latency: {metadata['metrics']['latencyMs']} milliseconds\")\n",
    "                print(\"---------- MetaData --------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5551fdd",
   "metadata": {},
   "source": [
    "### 4.3 System prompt를 함께 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1308ae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Role: assistant\n",
      "짜장면 만드는 방법을 알려드리겠습니다:\n",
      "\n",
      "재료:\n",
      "- 면\n",
      "- 돼지고기\n",
      "- 양파\n",
      "- 대파\n",
      "- 춘장\n",
      "- 전분\n",
      "- 설탕\n",
      "- 간장\n",
      "\n",
      "조리 순서:\n",
      "1. 돼지고기를 깍둑썰기로 자르기\n",
      "2. 양파도 같은 크기로 썰기\n",
      "3. 팬에 기름 두르고 돼지고기 볶기\n",
      "4. 양파 넣고 함께 볶기\n",
      "5. 춘장 넣고 볶기\n",
      "6. 물과 전분 섞어 소스 농도 맞추기\n",
      "7. 삶은 면 위에 소스 얹어내기\n",
      "\n",
      "팁: \n",
      "- 소스는 중간 불에서 천천히 볶기\n",
      "- 면은 살짝 단단하게 삶기\n",
      "\n",
      "맛있게 드세요!\n",
      "Stop reason: end_turn\n",
      "\n",
      "---------- MetaData --------------\n",
      "Input tokens: 47\n",
      "Output tokens: 278\n",
      "Total tokens: 325\n",
      "Latency: 5217 milliseconds\n",
      "---------- MetaData --------------\n"
     ]
    }
   ],
   "source": [
    "ModelInvoke(user_messages=\"짜장면 요리법 알려줘\",\n",
    "            system_prompt=\"중식당 사장님으로써 성실한 조언을 해야 합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f22f6",
   "metadata": {},
   "source": [
    "### 4.4 Inference parameter를 함께 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76493a35",
   "metadata": {},
   "source": [
    "- temperature 값을 1 로 높일수록 다양한 아이디어를 생성하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "09436730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Role: assistant\n",
      "여기 선생님이 도와드릴게요! \n",
      "\n",
      "🐰🐢 토끼와 거북이 경주 이야기 🏃‍♂️\n",
      "\n",
      "느림보 거북이와 자신만만한 토끼가 숲속 작은 길에서 승부를 겨루는데, 토끼는 앞서 달리다 자만심에 잠들고 성실한 거북이는 꾸준히 달려 결국 승리를 거머쥐었답니다.\n",
      "Stop reason: end_turn\n",
      "\n",
      "---------- MetaData --------------\n",
      "Input tokens: 68\n",
      "Output tokens: 154\n",
      "Total tokens: 222\n",
      "Latency: 3907 milliseconds\n",
      "---------- MetaData --------------\n"
     ]
    }
   ],
   "source": [
    "ModelInvoke(user_messages=\"토끼와 거북이가 경주하는 모습을 한문장에 6줄이내로 표현해줘!\",\n",
    "            system_prompt=\"유치원 선생님으로써 친절하게 이야기해줘!\",\n",
    "            inference_config={\"temperature\": 1.0},\n",
    "            additional_model_fields={\"top_k\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f55ad070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Role: assistant\n",
      "LLM의 temperature 파라미터는 출력의 무작위성과 창의성을 조절하는 중요한 설정입니다. 다음은 temperature 활용 예시입니다:\n",
      "\n",
      "1. 낮은 Temperature (0.1-0.3)\n",
      "- 보다 일관되고 결정론적인 응답\n",
      "- 사실적이고 정확한 정보 생성\n",
      "- 학술 논문, 기술 문서 작성에 적합\n",
      "\n",
      "예시:\n",
      "```python\n",
      "response = model.generate(\n",
      "    prompt=\"Python의 리스트 정렬 방법을 설명해줘\",\n",
      "    temperature=0.2  # 정확하고 표준적인 설명\n",
      ")\n",
      "```\n",
      "\n",
      "2. 중간 Temperature (0.5-0.7)\n",
      "- 균형 잡힌 창의성과 일관성\n",
      "- 일반적인 대화나 콘텐츠 생성에 적합\n",
      "\n",
      "예시:\n",
      "```python\n",
      "response = model.generate(\n",
      "    prompt=\"여름 휴가로 추천하는 여행지\",\n",
      "    temperature=0.6  # 다양하고 흥미로운 제안\n",
      ")\n",
      "```\n",
      "\n",
      "3. 높은 Temperature (0.8-1.0)\n",
      "- 매우 창의적이고 다양한 응답\n",
      "- 브레인스토밍, 창작 글쓰기에 적합\n",
      "\n",
      "예시:\n",
      "```python\n",
      "response = model.generate(\n",
      "    prompt=\"SF 단편소설의 독창적인 줄거리\",\n",
      "    temperature=0.9  # 매우 독특하고 창의적인 아이디어\n",
      ")\n",
      "```\n",
      "\n",
      "이렇게 temperature를 조절하여 원하는 출력 스타일을 얻을 수 있습니다.\n",
      "Stop reason: end_turn\n",
      "\n",
      "---------- MetaData --------------\n",
      "Input tokens: 29\n",
      "Output tokens: 490\n",
      "Total tokens: 519\n",
      "Latency: 8618 milliseconds\n",
      "---------- MetaData --------------\n"
     ]
    }
   ],
   "source": [
    "ModelInvoke(user_messages=\"LLM에서 temperature를 활용한 예문을 알려줘!\",\n",
    "            inference_config={\"temperature\": 0.1},\n",
    "            additional_model_fields={\"top_k\": 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d138bd6d",
   "metadata": {},
   "source": [
    "## 5. 도구 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b8472",
   "metadata": {},
   "source": [
    "### 5.1 Tool 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5aeb4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 현재 시간을 반환하는 함수 정의 (Funtion Tool)\n",
    "def get_current_time():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e516eff",
   "metadata": {},
   "source": [
    "### 5.2 Tool 과 Messagess를 Model에게 전달 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8751b2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Tool 요청이 있는 메세지, 'toolUse' 확인 ----------------------------------\n",
      "{'role': 'assistant', 'content': [{'text': '현재 시간을 확인하겠습니다.'}, {'toolUse': {'toolUseId': 'tooluse_Ff189nxSSW6_ESBKCiH_fA', 'name': 'get_current_time', 'input': {}}}]}\n",
      "---------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Tool을 정의함.\n",
    "tools = [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"get_current_time\",\n",
    "            \"description\": \"현재 시간을 반환합니다\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {},\n",
    "                    \"required\": []\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# 메시지 정의\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"현재 시간이 몇 시인가요?\"}]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Converse API 호출 하면서 Tool 요청 \n",
    "response = bedrock.converse(\n",
    "    modelId=base_model,\n",
    "    messages=messages,\n",
    "    toolConfig={\"tools\": tools}\n",
    ")\n",
    "\n",
    "# 응답 처리\n",
    "output_message = response['output']['message']\n",
    "print(\"------------------ Tool 요청이 있는 메세지, 'toolUse' 확인 ----------------------------------\")\n",
    "print(output_message)\n",
    "print(\"---------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e973250c",
   "metadata": {},
   "source": [
    "### 5.2 모델의 Tool사용 요청을 받아 Tool실행후 모델에게 전달 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79d95f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 시간을 확인하겠습니다.\n",
      "현재 시간은 21시 05분 13초입니다.\n",
      "\n",
      "------------------ 전체 대화 내용 확인  ----------------------------------\n",
      "{'role': 'user', 'content': [{'text': '현재 시간이 몇 시인가요?'}]}\n",
      "{'role': 'assistant', 'content': [{'text': '현재 시간을 확인하겠습니다.'}, {'toolUse': {'toolUseId': 'tooluse_Ff189nxSSW6_ESBKCiH_fA', 'name': 'get_current_time', 'input': {}}}]}\n",
      "{'role': 'user', 'content': [{'toolResult': {'toolUseId': 'tooluse_Ff189nxSSW6_ESBKCiH_fA', 'content': [{'text': '2025-09-28 21:05:13'}]}}]}\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 모델의 응답으로 부터 Tool 사용('toolUse') 요청이 있는지 확인하고 tool요청이 있으면 funtion tool을 실행한다. \n",
    "if 'content' in output_message:\n",
    "    for content in output_message['content']:\n",
    "        if 'toolUse' in content:\n",
    "            tool_use = content['toolUse']\n",
    "            tool_name = tool_use['name']\n",
    "\n",
    "            # 현재 시간을 확인하는 Funtion Tool 실행\n",
    "            if tool_name == \"get_current_time\":\n",
    "                current_time = get_current_time()\n",
    "\n",
    "                # 이전 대화 목록에 Tool 실행(현재날짜와 시간정보)결과를 메시지에 추가\n",
    "                messages.append(output_message)\n",
    "                messages.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"toolResult\": {\n",
    "                                \"toolUseId\": tool_use['toolUseId'],\n",
    "                                \"content\": [{\"text\": current_time}]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "                # 모델에게 Tool 실행 결과와 대화기록을 함께 전달한다. \n",
    "                final_response = bedrock.converse(\n",
    "                    modelId=base_model,\n",
    "                    messages=messages,\n",
    "                    toolConfig={\"tools\": tools}\n",
    "                )\n",
    "\n",
    "                # 모델의 최종 응답 출력\n",
    "                final_content = final_response['output']['message']['content'][0]['text']\n",
    "                print(final_content)\n",
    "        else:\n",
    "            # Tool 사용 없이 직접 응답한 경우\n",
    "            print(content['text'])\n",
    "\n",
    "print(\"\\n------------------ 전체 대화 내용 확인  ----------------------------------\")\n",
    "for item in messages:\n",
    "    print(item)\n",
    "print(\"\\n\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
